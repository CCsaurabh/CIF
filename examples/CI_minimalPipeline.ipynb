{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite Indicators: Minimal Pipeline\n",
    "\n",
    "## 1. Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIBRARIES\n",
    "\n",
    "import os\n",
    "from cif import cif\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import warnings\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK AVAILABILITY\n",
    "\n",
    "print(os.environ['X13PATH']) # Check the availability of X-13ARIMA-SEATS model (downloaded from https://www.census.gov/srd/www/x13as/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "\n",
    "#os.chdir('C:/path/') # Set path to to folder, where the plots and logs should be saved\n",
    "\n",
    "bw = False # True for black and white visualisations\n",
    "\n",
    "country = 'CZE' # Select target country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT DIRECTORY\n",
    "\n",
    "strDate = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "outputDir = os.path.join('plots_' + country + '_' + strDate)\n",
    "os.makedirs(outputDir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Load\n",
    "\n",
    "Loading data from OECD API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all, subjects_all, measures_all = cif.createDataFrameFromOECD(countries = [country], dsname = 'MEI', frequency = 'M')\n",
    "data_rs, subjects_rs, measures_rs = cif.createDataFrameFromOECD(countries = [country], dsname = 'QNA', subject = ['B1_GE'], frequency = 'Q')\n",
    "\n",
    "print('Downloaded MEI data set size: %d x %d' % (data_all.shape[0], data_all.shape[1]))\n",
    "print('Downloaded reference data set size: %d x %d' % (data_rs.shape[0], data_rs.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.tail(12) # MEI database data from last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a) leading indicators: Component series\n",
    "\n",
    "colMultiInd = data_all.columns.names.index('subject')\n",
    "\n",
    "ind_LOCO = subjects_all['id'].apply(lambda x: re.search(r'\\bLOCO', x) != None)\n",
    "subjects_LOCO = subjects_all[ind_LOCO]\n",
    "\n",
    "\n",
    "# 1b) Leading indicators: Reference series\n",
    "\n",
    "ind_LORS = subjects_all['id'].apply(lambda x: re.search(r'\\bLORS', x) != None)\n",
    "subjects_LORS = subjects_all[ind_LORS]\n",
    "\n",
    "\n",
    "# 1c) Leading indicators: CLI\n",
    "\n",
    "ind_LOLI = subjects_all['id'].apply(lambda x: re.search(r'\\bLOLI', x) != None)\n",
    "subjects_LOLI = subjects_all[ind_LOLI]\n",
    "\n",
    "\n",
    "# 1d) Candidate time series\n",
    "\n",
    "subjects_adj = subjects_all[-(ind_LOCO | ind_LORS | ind_LOLI)]\n",
    "data_adj = data_all.loc[ : , [x for x in data_all.columns if x[colMultiInd] in list(subjects_adj['id'])]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Transformations\n",
    "\n",
    "### 3.1 Reference Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) DATA TRANSFORMATIONS\n",
    "\n",
    "# 2.1) REFERENCE SERIES\n",
    "\n",
    "# 2.1a) Priority list of reference series (GDP) and frequency conversion\n",
    "\n",
    "rsPriorityList = [ 'LNBQRSA' # Best fit with OECD reference series\n",
    "                , 'CQR'\n",
    "                , 'LNBQR'\n",
    "                , 'DNBSA'\n",
    "                , 'DOBSA'\n",
    "                , 'CQRSA'\n",
    "                , 'CARSA'\n",
    "                , 'GPSA'\n",
    "                , 'GYSA'\n",
    "                , 'CPCARSA'\n",
    "                , 'VIXOBSA'\n",
    "                , 'VOBARSA'\n",
    "                , 'VPVOBARSA'\n",
    "                , 'HCPCARSA'\n",
    "                , 'HVPVOBARSA'\n",
    "                ]\n",
    "\n",
    "if (data_rs.shape[0] > 0):\n",
    "    \n",
    "    rsq = cif.getOnlyBestMeasure(df = data_rs, priorityList = rsPriorityList)\n",
    "    rsq = cif.getRidOfMultiindex(df = rsq)\n",
    "    rsq = cif.renameQuarterlyIndex(df = rsq)\n",
    "    rsq = cif.getIndexAsDate(df = rsq)\n",
    "    rs = cif.createMonthlySeries(df = rsq)\n",
    "    rs.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rs.tail(4) # all available measures of the reference series (last year, quaterly series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.tail(12) # selected measure of the reference series (last year, monthly series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1b) Seasonal adjustment, outlier filtering and short-term prediction\n",
    "#   & Cycle identification (Hodrick-Prescott filter)\n",
    "#   & Normalisation\n",
    "\n",
    "fileLogs = open(os.path.join(outputDir, country + '_fileLogs_rsTransformation.txt'), 'w')\n",
    "rs_SA_HP_norm = cif.pipelineTransformations(rs, showPlots = False, savePlots = outputDir, saveLogs = fileLogs)\n",
    "fileLogs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2) INDIVIDUAL INDICATORS\n",
    "\n",
    "# 2.2a) Priority list of OECD available measures\n",
    "\n",
    "priorityList = ['NCML'\n",
    "                , 'ML'\n",
    "                , 'CXML'\n",
    "                , 'ST'\n",
    "                , 'NCCU'\n",
    "                , 'CXCU'\n",
    "                , 'IXOB'\n",
    "                , 'NCMLSA'\n",
    "                , 'MLSA'\n",
    "                , 'CXMLSA'\n",
    "                , 'STSA'\n",
    "                , 'NCCUSA'\n",
    "                , 'CXCUSA'\n",
    "                , 'IXOBSA'\n",
    "                , 'IXNSA'\n",
    "                , 'GP'\n",
    "                , 'GY']\n",
    "\n",
    "if data_adj.shape[0] > 0:\n",
    "    \n",
    "    data = cif.getOnlyBestMeasure(df = data_adj, priorityList = priorityList)\n",
    "    data = cif.getRidOfMultiindex(df = data)\n",
    "    data = cif.getIndexAsDate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2b) Seasonal adjustment, outlier filtering and short-term prediction\n",
    "#   & Cycle identification (Hodrick-Prescott filter)\n",
    "#   & Normalisation\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "            \n",
    "    warnings.simplefilter(\"ignore\")\n",
    "            \n",
    "    fileLogs = open(os.path.join(outputDir, 'fileLogs_dataTransformation.txt'), 'w')\n",
    "    data_SA_HP_norm = cif.pipelineTransformations(df = data, showPlots = False, savePlots = outputDir, saveLogs = fileLogs, createInverse = True) \n",
    "    fileLogs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) TURNING-POINT DETECTION (Bry-Boschan algorithm)\n",
    "\n",
    "# 3.1) REFERENCE SERIES\n",
    "\n",
    "fileLogs = open(os.path.join(outputDir, country + '_fileLogs_rsEvaluation.txt'), 'w')\n",
    "rs_ind_turningPoints = cif.pipelineTPDetection(df = rs_SA_HP_norm, printDetails = False, showPlots = False, savePlots = outputDir, saveLogs = fileLogs)\n",
    "fileLogs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(os.path.join(outputDir, 'CZE_B1_GE_LNBQRSA' + '_05_ext.png')) # change name of the series here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2) INDIVIDUAL INDICATORS\n",
    "\n",
    "fileLogs = open(os.path.join(outputDir, 'fileLogs_dataEvaluation.txt'), 'w')\n",
    "data_ind_turningPoints = cif.pipelineTPDetection(df = data_SA_HP_norm, origColumns = list(data.columns), printDetails = False, showPlots = False, savePlots = outputDir, saveLogs = fileLogs)\n",
    "fileLogs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(os.path.join(outputDir, 'CZE_BCBUTE02_STSA' + '_05_ext.png')) # # change name of the series here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) TURNING-POINTS MATCHING\n",
    "\n",
    "fileLogs = open(os.path.join(outputDir, country + '_fileLogs_tpMatching.txt'), 'w')\n",
    "data_ind_extOrd, data_ind_time, data_ind_missing, data_ind_missingEarly, data_ind_extra = cif.pipelineTPMatching(df1 = rs_SA_HP_norm, df2 = data_SA_HP_norm, ind1 = rs_ind_turningPoints, ind2 = data_ind_turningPoints, printDetails = False, showPlots = False, savePlots = outputDir, saveLogs = fileLogs, nameSuffix = '_06_matching' + '_rs' + country)\n",
    "fileLogs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(os.path.join(outputDir, 'CZE_BCBUTE02_STSA' + '_06_matching_rsCZE.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) EVALUATION\n",
    "\n",
    "data_totalEval, data_selectedEval, data_selectedCol = cif.pipelineEvaluation(df1 = rs_SA_HP_norm, df2 = data_SA_HP_norm, missing = data_ind_missing, missingEarly = data_ind_missingEarly, extra = data_ind_extra, time = data_ind_time, maxInd = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selectedEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) AGGREGATION & FINAL EVALUATION \n",
    "\n",
    "# 6a) CLI construction\n",
    "\n",
    "agg_cMat = data_SA_HP_norm.loc[:, data_selectedCol] # value of the de-trended, smoothed and normalised component\n",
    "\n",
    "CLI = cif.pipelineCreateCLI(agg_cMat).rename(columns = {'CLI': country + '_CLI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cif.compareTwoSeries(CLI, rs_SA_HP_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6b) CLI turning points\n",
    "\n",
    "fileLogs = open(os.path.join(outputDir, country + '_fileLogs_CLIEvaluation.txt'), 'w')\n",
    "CLI_ind_turningPoints = cif.pipelineTPDetection(CLI, printDetails = False, showPlots = False, savePlots = outputDir, saveLogs = fileLogs)\n",
    "fileLogs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6c) Match turning points\n",
    "\n",
    "CLI_ind_extOrd, CLI_ind_time, CLI_ind_missing, CLI_ind_missingEarly, CLI_ind_extra = cif.pipelineTPMatching(df1 = rs_SA_HP_norm, df2 = CLI, ind1 = rs_ind_turningPoints, ind2 = CLI_ind_turningPoints, showPlots = False, savePlots = outputDir, nameSuffix = '_06_matching' + '_rs' + country, bw = bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(os.path.join(outputDir, 'CZE_CLI' + '_06_matching_rsCZE.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6d) Basic characteristics\n",
    "    \n",
    "CLI_eval = cif.pipelineEvaluation(df1 = rs_SA_HP_norm, df2 = CLI, missing = CLI_ind_missing, missingEarly = CLI_ind_missingEarly, extra = CLI_ind_extra, time = CLI_ind_time, evalOnly = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLI_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
